{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# environmentName will be used at different places in the notebook\n",
    "environmentName = \"04-regression\"\n",
    "Pkg.activate(joinpath(dirname(pwd()), \"conf\", environmentName))\n",
    "Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, Plots, StatsBase\n",
    "using RDatasets\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "First we are gonna load the datset `cars` from the `RDatasets` package and display the variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cars = dataset(\"datasets\", \"cars\");\n",
    "names(data_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(data_cars,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data point consists of speed and distance values which which indicates a linear relation as: speed is more or less distance over time. We are gonna choose a linear model:\n",
    "\n",
    "$$f_\\theta(x) =  a x + b$$\n",
    "\n",
    "with $\\theta =(a,b)\\in\\mathbb R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(data_cars[:,\"Speed\"], data_cars[:,\"Dist\"], \n",
    "            legend=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to estimate $\\theta$. Note that both speed and distance are scalars or 1-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1; N = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the data into a test and training set we randomly choose $75\\%$ of the dataset as training data and the remainder as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = size(data_cars, 1)\n",
    "n = round(Int, k * 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X`is gonna contain the speed training data and `Y` the distance training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_training = sample(1:k, n, replace = false)\n",
    "X = data_cars[i_training,\"Speed\"]\n",
    "Y = data_cars[i_training,\"Dist\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we use `X_test` and `Y_test` for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_test = setdiff(1:k, i_training)\n",
    "X_test = data_cars[i_test,\"Speed\"]\n",
    "Y_test = data_cars[i_test,\"Dist\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Our deterministic model is $f:\\mathbb R^D \\to \\mathbb R^N$ or to be more clear since $D = N = 1$ and $\\theta = (a, b)$ it is $f: \\mathbb{R} \\to \\mathbb{R}, x \\mapsto ax + b$ with $x$ referring to the speed and $f(x)$ referring to the distance. We choose `Number` as the datatype for $x$ since $N = 1$. We can extend the use of $f$ via [Mutiple Dispatch](https://docs.julialang.org/en/v1/manual/methods/). If $x$ is a `Number` then the first defintion of $f$ will be used. If $X$ is a `Vector` then the second defintion will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x::Number, θ) = θ[2] * x + θ[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(X::Vector, θ) = [f(x, θ) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to the original problem: We also want to define the statistical model with variance $\\sigma^2=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ² = 10\n",
    "s = sqrt(σ²)\n",
    "Φ(x::Number, θ) = s * randn() + f(x, θ)\n",
    "Φ(X::Vector, θ) = [Φ(x, θ) for x in X];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ω = [ones(n) X];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    "Let's traing our model with both methods.\n",
    "\n",
    "### Empirical Risk Minimization\n",
    "\n",
    "ERM estimates $\\theta = \\Omega^\\dagger Y$. We can use the builtin \"solve\" operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_ERM = Ω \\ Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERM estimates the parameters of $f_\\theta(x)=ax+b$ as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"a = $(θ_ERM[2]), b = $(θ_ERM[1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the estimated function together with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = collect((minimum(X)-1):0.5:(maximum(X)+1))\n",
    "\n",
    "scatter(X,Y, legend=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "plot!(p, f(p, θ_ERM), lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also have a look at the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = collect((minimum(X_test)-1):0.5:(maximum(X_test)+1))\n",
    "\n",
    "scatter(X_test,Y_test, legend=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "plot!(p, f(p, θ_ERM), lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge-Regression (RR) with parameter $\\lambda$ is calculated as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_T(λ) = (Ω' * Ω + (n*λ) .* diagm(ones(D+1))) \\ (Ω' * Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna plot the RR-estimator for different $\\lambda$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = collect((minimum(X)-1):0.5:(maximum(X)+1))\n",
    "\n",
    "anim = @animate for λ in 0:0.02:0.25\n",
    "    scatter(X,Y, label=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "    plot!(p, f(p, θ_T(λ)), lw = 2, label = \"λ = $λ\")\n",
    "    ylims!(0,100)\n",
    "end\n",
    "gif(anim, joinpath(dirname(pwd()), \"img\", environmentName, \"ridge_regression_1.gif\"), fps = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The animation suggests $\\lambda=0.2$ is an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_RR = θ_T(0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in the RR estimation for $f_\\theta(x)=ax+b$ as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"a = $(θ_RR[2]), b = $(θ_RR[1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood und Maximum a-Posteriori Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter of Maximum Likelihood (ML) is `θ_ERM` and the parameter of Maximum a-Posteriori Estimation (MAP) is `θ_T(λ)` with $\\lambda = \\sigma^2/n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_ML = θ_ERM\n",
    "θ_MAP = θ_T(σ²/n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can insert these parameters into our statistical model and then sample from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = Φ(p, θ_ML)\n",
    "a2 =  Φ(p, θ_MAP)\n",
    "scatter(X,Y, label = \"data\", legend = (0.2,0.8),\n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "scatter!(p, a1, lw = 2, c = :indianred, label =\"ML\")\n",
    "scatter!(p, a2, lw = 2, c = :seagreen, label = \"MAP\")\n",
    "plot!(p, a1, lw = 2, c = :indianred, label = false)\n",
    "plot!(p, a2, lw = 2, c = :seagreen, label = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to estimate the relation of `Dist` und `Speed` using a neural network with ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ(z) = max(0,z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna choose depth 2 with linear parts $\\mathbb R^1\\to \\mathbb R^2$ and $\\mathbb R^2\\to \\mathbb R^1$. This very simple neural network will be sufficient for this linear relationship and is defined as follows:\n",
    "$$\n",
    "    y_\\theta(x) = \\text{ReLU.}\\left (x \\begin{pmatrix}\n",
    "            \\theta_1 \\\\\n",
    "            \\theta_2\n",
    "        \\end{pmatrix} + \\begin{pmatrix}\n",
    "            \\theta_3 \\\\\n",
    "            \\theta_4\n",
    "        \\end{pmatrix}\n",
    "        \\right ) \\\\\n",
    "    \\text{NN}_\\theta(x) = z_\\theta(x) = \\text{ReLU} \\left (\n",
    "        (\\theta_5, \\theta_6) y(x) + \\theta_7      \n",
    "    \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function f_NN(x::Number, θ)\n",
    "    A, b = reshape(θ[1:2], 2, 1), θ[3:4]\n",
    "    y = σ.(A * x + b)\n",
    "    \n",
    "    A, b = reshape(θ[5:6], 1, 2), θ[7:7]\n",
    "    z = σ.(A * y + b)\n",
    "    \n",
    "    z[1]\n",
    "end\n",
    "f_NN(X::Vector, θ) = [f_NN(x, θ) for x in X];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not have a closed formula to calculate `θ_ERM` for the neural network we have to estimate `θ_ERM` using optimization methods. For this we use the `optimize` function from the package `Optim.jl` as a blackbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_NN(θ, X, Y) = mean((f_NN(X, θ) - Y).^2)\n",
    "o = optimize(θ -> R_NN(θ, X, Y), rand(7))\n",
    "θ_NN = Optim.minimizer(o);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network estimates a function that we can visualise using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = collect((minimum(X)-1):0.5:(maximum(X)+1))\n",
    "\n",
    "scatter(X,Y, legend=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "plot!(p, f_NN(p, θ_NN), lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = collect((minimum(X_test)-1):0.5:(maximum(X_test)+1))\n",
    "\n",
    "scatter(X_test,Y_test, legend=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "plot!(p, f_NN(p, θ_NN), lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have several models to choose from. Lets have a look at which models is most appropriate for our goal. For this we  first visually compare all models on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_test,Y_test, legend=1,\n",
    "            label = false,\n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "plot!(p, f(p, θ_ERM), lw = 2, label = \"ERM\")\n",
    "plot!(p, f(p, θ_RR), lw = 2, label = \"RR\")\n",
    "plot!(p, Φ(p, θ_ML), lw = 2, label = \"ML\")\n",
    "plot!(p, Φ(p, θ_MAP), lw = 2, label = \"MAP\")\n",
    "plot!(p, f_NN(p, θ_NN), lw = 2, label = \"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantify the performance of each model on the test  and training data we calculate the empirical risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R(θ, f, X, Y) = mean((f(X, θ) - Y).^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [(R(θ, f, X_test, Y_test), R(θ, f, X, Y)) for θ in [θ_ERM, θ_RR]]   \n",
    "println(\"ERM test data risk: $(r[1][1])\\n\")\n",
    "println(\"ERM train data risk: $(r[1][2])\\n\")\n",
    "println(\"ERM risk ratio: $(r[1][1]/r[1][2])\\n\")\n",
    "println(\"RR test data risk: $(r[2][1])\\n\")\n",
    "println(\"RR train data risk: $(r[2][2])\\n\")\n",
    "println(\"RR risk ratio: $(r[2][1]/r[2][2])\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot properly distinguish the results of ERM and RR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural model evaluates as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (R(θ_NN, f_NN, X_test, Y_test), R(θ_NN, f_NN, X, Y))\n",
    "println(\"NN test data risk: $(r[1])\\n\")\n",
    "println(\"NN train data risk: $(r[2])\\n\")\n",
    "println(\"NN risk ratio: $(r[1]/r[2])\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Regularisation\n",
    "\n",
    "Lets have a look at a syncthetic example to see why it is important to regularise. The data will be sampled from a cubic polynomial with added noise ($n = 20$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (x -> 1 + 4*x + 2*x^2 - 0.5*x^3)\n",
    "\n",
    "n = 20\n",
    "P = 4\n",
    "X = 10 .* (rand(n) .- 0.5); # randn sampled von Unif([-5,5])\n",
    "Y = map(q, X) + 5 .* randn(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the sampes and the cubic polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(q, label = \"q\", size = (600,300), linestyle = :dash, color = :steelblue)\n",
    "scatter!(X,Y, label=false, color = :blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the feature matrix and the RR parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ω = hcat([X.^i for i in 0:P-1]...)\n",
    "θ_T(λ) = (Ω' * Ω + (n*λ) .* diagm(ones(P))) \\ (Ω' * Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each value of $\\lambda$ induces a polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q(λ) = (x -> sum(θ * x^(i-1) for (i,θ) in enumerate(θ_T(λ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The animation suggests that regularisation ($\\lambda >0$) improves the results compared to no regularisation ($\\lambda =0$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = @animate for λ in 0:10\n",
    "    plot(q, label = \"q\", size = (600,300), linestyle = :dash, lw = 2,\n",
    "        color = :steelblue, \n",
    "        xlims = (-5,5),\n",
    "        ylims = (-20, 120))\n",
    "    scatter!(X,Y, label=false, color = :blue)\n",
    "    plot!(Q(λ/n), label = \"λ = $(λ/n)\", color = :red, lw = 2)\n",
    "end\n",
    "gif(anim, joinpath(dirname(pwd()), \"img\", environmentName, \"ridge_regression_2.gif\"), fps = 2)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
