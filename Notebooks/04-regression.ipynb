{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# environmentName wird an einigen Stellen im Notebook verwendet\n",
    "environmentName = \"04-regression\"\n",
    "Pkg.activate(joinpath(dirname(pwd()), \"conf\", environmentName))\n",
    "Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, Plots, StatsBase\n",
    "using RDatasets\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Wir laden den Datensatz `cars` aus dem `RDatasets` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cars = dataset(\"datasets\", \"cars\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen zunächst, welche Variablen in diesem Datensatz erhalten sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(data_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(data_cars,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datenpunkte stellen also Geschwindigkeit und zurückgelegte Distanz dar. \n",
    "\n",
    "Wir erwarten einen linearen Zusammenhang, also wählen wir das lineare Modell\n",
    "\n",
    "$$f_\\theta(x) =  a x + b$$\n",
    "\n",
    "mit $\\theta =(a,b)\\in\\mathbb R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(data_cars[:,\"Speed\"], data_cars[:,\"Dist\"], \n",
    "            legend=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen die lineare Abhängigkeit dieser Variablen mittels Regression schätzen.\n",
    "\n",
    "Beide Variablen sind eindimensional. D.h:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1; N = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufteilen der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir teilen die Daten in Trainings- und Testdaten auf.\n",
    "\n",
    "Die Wahl soll zufällig sein und $75\\%$ der Daten sollen Trainingsdaten sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = size(data_cars, 1)\n",
    "n = round(Int, k * 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Trainingsdaten speichern wir in den Vektoren `X` und `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_training = sample(1:k, n, replace = false)\n",
    "X = data_cars[i_training,\"Speed\"]\n",
    "Y = data_cars[i_training,\"Dist\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Testdaten speichern wir in den Vektoren `X_test` und `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_test = setdiff(1:k, i_training)\n",
    "X_test = data_cars[i_test,\"Speed\"]\n",
    "Y_test = data_cars[i_test,\"Dist\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition des Modells\n",
    "\n",
    "Wir definieren nun das deterministische lineare Modell $f:\\mathbb R^D \\to \\mathbb R^N$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x::Number, θ) = θ[2] * x + θ[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da $N=1$ können wir für `x` den Typ `Number` angeben. \n",
    "\n",
    "Es wird später außerdem hilfreich sein, per Multiple-Dispatch die Definition von `f` auf Vektoren zu erweitern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(X::Vector, θ) = [f(x, θ) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir definieren weiterhin das statistische Modell für die Varianz $\\sigma^2=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ² = 10\n",
    "s = sqrt(σ²)\n",
    "Φ(x::Number, θ) = s * randn() + f(x, θ)\n",
    "Φ(X::Vector, θ) = [Φ(x, θ) for x in X];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir definieren außerdem die Feature Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ω = [ones(n) X];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt trainieren wir unser Modell mit verschiedenen Methoden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical Risk Minimization\n",
    "\n",
    "Bei ERM ist der Parameter durch $\\theta = \\Omega^\\dagger Y$ gegeben.\n",
    "\n",
    "Wir berechnen diesen Parameter wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_ERM = Ω \\ Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERM hat die folgenden Parameter für $f_\\theta(x)=ax+b$ geschätzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"a = $(θ_ERM[2]), b = $(θ_ERM[1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir visualieren die geschätzte Funktion zusammen mit den Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = collect((minimum(X)-1):0.5:(maximum(X)+1))\n",
    "\n",
    "scatter(X,Y, legend=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "plot!(p, f(p, θ_ERM), lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Ridge-Regression Schätzer mit Parameter $\\lambda$ wird wie folgt berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_T(λ) = (Ω' * Ω + (n*λ) .* diagm(ones(D+1))) \\ (Ω' * Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir plotten den RR-Schätzer für verschiedene Werte von $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = @animate for λ in 0:0.02:0.25\n",
    "    scatter(X,Y, label=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "    plot!(p, f(p, θ_T(λ)), lw = 2, label = \"λ = $λ\")\n",
    "    ylims!(0,100)\n",
    "end\n",
    "gif(anim, joinpath(\"img\", environmentName, \"ridge_regression_1.gif\"), fps = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Animation nach zu urteilen scheint $\\lambda=0.2$ eine gute Wahl zu sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_RR = θ_T(0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RR hat die folgenden Parameter für $f_\\theta(x)=ax+b$ geschätzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"a = $(θ_RR[2]), b = $(θ_RR[1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood und Maximum a-Posteriori Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Parameter für ML ist durch `θ_ERM` bestimmt\n",
    "\n",
    "Der Parameter für MAP ist durch `θ_T(λ)` für $\\lambda = \\sigma^2/n$ bestimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_ML = θ_ERM\n",
    "θ_MAP = θ_T(σ²/n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können wir diese Parameter in das statistische Modell einsetzen und von diesem samplen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = Φ(p, θ_ML)\n",
    "a2 =  Φ(p, θ_MAP)\n",
    "scatter(X,Y, label = \"data\", legend = (0.2,0.8),\n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "scatter!(p, a1, lw = 2, c = :indianred, label =\"ML\")\n",
    "scatter!(p, a2, lw = 2, c = :seagreen, label = \"MAP\")\n",
    "plot!(p, a1, lw = 2, c = :indianred, label = false)\n",
    "plot!(p, a2, lw = 2, c = :seagreen, label = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt wollen wir die Abhängigkeit von `Dist` und `Speed` durch ein neuronales Netz bestimmen.\n",
    "\n",
    "Wir verwenden die ReLu Activation Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ(z) = max(0,z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir definieren das Modell durch ein neuronales Netz von Tiefe 2 und mit inneren Layer, der durch lineare Funktionen $\\mathbb R^1\\to \\mathbb R^2$ und $\\mathbb R^2\\to \\mathbb R^1$ gegeben ist. \n",
    "\n",
    "Dies ist ein sehr simples neuronales Netz, eignet sich daher aber gut um die Funktionsweise zu veranschaulichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function f_NN(x::Number, θ)\n",
    "    A, b = reshape(θ[1:2], 2, 1), θ[3:4]\n",
    "    y = σ.(A * x + b)\n",
    "    \n",
    "    A, b = reshape(θ[5:6], 1, 2), θ[7:7]\n",
    "    z = σ.(A * y + b)\n",
    "    \n",
    "    z[1]\n",
    "end\n",
    "f_NN(X::Vector, θ) = [f_NN(x, θ) for x in X];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir für das neuronale Netz keine geschlossene Form für den ERM-Schätzer `θ_ERM` haben, müssen wir `θ_ERM` durch Optimierungsmethoden bestimmen.\n",
    "\n",
    "Wir werden die Blackbox `optimize` Funktion aus dem Package `Optim.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_NN(θ, X, Y) = mean((f_NN(X, θ) - Y).^2)\n",
    "o = optimize(θ -> R_NN(θ, X, Y), rand(7))\n",
    "θ_NN = Optim.minimizer(o);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das neuronale Netz hat nun eine Funktion geschätzt, die wir wieder zusammen mit den Trainingsdaten visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X,Y, legend=false, \n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "plot!(p, f_NN(p, θ_NN), lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt wollen wir beurteilen, welches Modell am besten geeignet ist, um die Daten zu beschreiben. Dazu evaluieren wir die Schätzer auf den Testdaten.\n",
    "\n",
    "Zuerst plotten wir alle geschätzten Funktionen zusammen mit den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_test,Y_test, legend=1,\n",
    "            label = false,\n",
    "            xlabel = \"Speed\",\n",
    "            ylabel = \"Dist\",\n",
    "            size = (600,300))\n",
    "plot!(p, f(p, θ_ERM), lw = 2, label = \"ERM\")\n",
    "plot!(p, f(p, θ_RR), lw = 2, label = \"RR\")\n",
    "plot!(p, Φ(p, θ_ML), lw = 2, label = \"ML\")\n",
    "plot!(p, Φ(p, θ_MAP), lw = 2, label = \"MAP\")\n",
    "plot!(p, f_NN(p, θ_NN), lw = 2, label = \"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu beurteilen, welches Modell wie gut funktioniert, definieren wir das empirische Risiko."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R(θ, f, X, Y) = mean((f(X, θ) - Y).^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das empirische Risiko für Trainings- und Testdaten im deterministischen linearen Modell ist wie folgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [(R(θ, f, X_test, Y_test), R(θ, f, X, Y)) for θ in [θ_ERM, θ_RR]]   \n",
    "println(\"Risiko Testdaten ERM: $(r[1][1])\\n\")\n",
    "println(\"Risiko Trainingsdaten ERM: $(r[1][2])\\n\")\n",
    "println(\"ERM Risikoverhältnis: $(r[1][1]/r[1][2])\\n\")\n",
    "println(\"Risiko Testdaten RR: $(r[2][1])\\n\")\n",
    "println(\"Risiko Trainingsdaten RR: $(r[2][2])\\n\")\n",
    "println(\"RR Risikoverhältnis: $(r[2][1]/r[2][2])\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das neuronale Netz ergeben sich folgende Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (R(θ_NN, f_NN, X_test, Y_test), R(θ_NN, f_NN, X, Y))\n",
    "println(\"Risiko Testdaten NN: $(r[1])\\n\")\n",
    "println(\"Risiko Trainingsdaten NN: $(r[2])\\n\")\n",
    "println(\"NN Risikoverhältnis: $(r[1]/r[2])\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Regularisierung\n",
    "\n",
    "In obigem Beispiel sehen wir keinen großen Unterschied zwischen ERM und RR. \n",
    "\n",
    "Es folgt ein Beispiel, für das Regularisierung wichtig ist.\n",
    "\n",
    "Dazu generieren wir $n=20$ synthetische Daten von einem kubischen Polynom plus Noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (x -> 1 + 4*x + 2*x^2 - 0.5*x^3)\n",
    "\n",
    "n = 20\n",
    "P = 4\n",
    "X = 10 .* (rand(n) .- 0.5); # randn sampled von Unif([-5,5])\n",
    "Y = map(q, X) + 5 .* randn(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir plotten die Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(q, label = \"q\", size = (600,300), linestyle = :dash, color = :steelblue)\n",
    "scatter!(X,Y, label=false, color = :blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir berechnen Feature Matrix und RR Parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ω = hcat([X.^i for i in 0:P-1]...)\n",
    "θ_T(λ) = (Ω' * Ω + (n*λ) .* diagm(ones(P))) \\ (Ω' * Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für jeden Wert von $\\lambda$ erhalten wir dann ein Polynom wie folgt:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q(λ) = (x -> sum(θ * x^(i-1) for (i,θ) in enumerate(θ_T(λ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folgende Animation zeigt, dass Regularisierung ($\\lambda >0$) ein besseres Ergebnis als keine Regularisierung ($\\lambda =0$) erzielt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = @animate for λ in 0:10\n",
    "    plot(q, label = \"q\", size = (600,300), linestyle = :dash, lw = 2,\n",
    "        color = :steelblue, \n",
    "        xlims = (-5,5),\n",
    "        ylims = (-20, 120))\n",
    "    scatter!(X,Y, label=false, color = :blue)\n",
    "    plot!(Q(λ/n), label = \"λ = $(λ/n)\", color = :red, lw = 2)\n",
    "end\n",
    "gif(anim, joinpath(\"img\", environmentName, \"ridge_regression_2.gif\"), fps = 2)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
